#!/bin/bash -exu

SCRIPT_NAME=$(basename $0)
RUN_DIR=/var/vcap/sys/run/etcd
PIDFILE=${RUN_DIR}/etcd.pid

source /var/vcap/packages/etcd-common/utils.sh

source /var/vcap/jobs/etcd/bin/etcd_bosh_utils.sh

exec > >(tee -a >(logger -p user.info -t vcap.${SCRIPT_NAME}.stdout) | awk -W interactive '{ system("echo -n [$(date +\"%Y-%m-%d %H:%M:%S%z\")]"); print " " $0 }' >> ${LOG_DIR}/${SCRIPT_NAME}.log)
exec 2> >(tee -a >(logger -p user.error -t vcap.${SCRIPT_NAME}.stderr) | awk -W interactive '{ system("echo -n [$(date +\"%Y-%m-%d %H:%M:%S%z\")]"); print " " $0 }' >> ${LOG_DIR}/${SCRIPT_NAME}.err.log)

function wait_for_this_node_to_synchronize() {
  for i in $(seq 55); do
    if /var/vcap/packages/etcd/etcdctl ${etcdctl_sec_flags} -debug -C ${advertise_client_url} ls; then
      synced=true
      break
    fi
    sleep 1
  done
}

function handle_orphaned_etcd() {
  echo "killing etcd with pid ${etcd_pid}"
  kill "${etcd_pid}"
}

function start_and_sync_etcd() {
  /var/vcap/packages/etcd/etcd ${etcd_sec_flags}                                              \
      --name                        ${node_name}                                              \
      --data-dir                    ${DATA_DIR}                                               \
      --heartbeat-interval          <%= p("etcd.heartbeat_interval_in_milliseconds") %>       \
      --election-timeout            <%= p("etcd.election_timeout_in_milliseconds") %>         \
      --listen-peer-urls            ${listen_peer_url}                                        \
      --listen-client-urls          ${listen_client_url}                                      \
      --initial-advertise-peer-urls ${advertise_peer_url}                                     \
      --advertise-client-urls       ${advertise_client_url}                                   \
      --initial-cluster             ${cluster}                                                \
      --initial-cluster-state       ${cluster_state}                                          \
      2> >(tee -a ${LOG_DIR}/etcd.stderr.log | logger -p user.error -t vcap.etcd)             \
      1> >(tee -a ${LOG_DIR}/etcd.stdout.log | logger -p user.info  -t vcap.etcd) &

  etcd_pid=$!

  synced=false
  wait_for_this_node_to_synchronize # mutates $synced

  if ${synced}; then
    return
  else
    safe_teardown "${prior_member_list}"
    kill -9 ${etcd_pid}
    exit 1
  fi
}

# Verifies that the peer url in the etcd cluster for this node is correct, this may
# happen if the job name changes.
function verify_peer_url() {
  if [[ -z $(member_list | grep "name=${node_name} peerURLs=${advertise_peer_url}") ]]; then

    #TODO: correctly write to /etc/hosts
    #echo "127.0.0.1 $(current_peer_url)" >> /etc/hosts

    /var/vcap/packages/etcd/etcdctl ${etcdctl_sec_flags} -debug -C https://$(current_peer_url):4001 member update ${node_name} ${advertise_peer_url}
    sleep 2

    kill -9 ${etcd_pid}
    sleep 2

    start_and_sync_etcd
  fi
}

function main() {
  mkdir -p ${RUN_DIR}

  case $1 in

    start)
      trap handle_orphaned_etcd TERM

      <% if p("etcd.require_ssl") %>
        set +e
        /var/vcap/packages/etcd-dns-checker/bin/check-a-record <%= p("etcd.dns_health_check_host") %>
        if [ "0" != "$?" ]; then
          echo "DNS is not up"
          exit 1
        fi
        set -e
      <% end %>

      pid_guard ${PIDFILE} "etcd"

      <% if p("etcd.enable_network_diagnostics") %>
        set +e
        /var/vcap/jobs/etcd/bin/etcd_network_diagnostics_run_ctl.sh start
        set -e
      <% end %>

      if ! mountpoint -q ${STORE_DIR}; then
        echo "WARNING: $STORE_DIR is not on a persistent disk as recommended"
      fi

      export GOMAXPROCS=$(nproc)

      create_cert_files

      prior_member_list=$(member_list)

      if [ -z "${prior_member_list}" ]; then
        cluster_state=new
        cluster="${this_node}"
      else
        cluster_state=existing
        cluster=$(extract_cluster_from_member_list "${prior_member_list}")

        # If this node is not in the existing cluster, add it. It generally should
        # not be in the cluster, but if a prior shutdown failed to remove it, we
        # don't want to have it duplicated in the list (etcd server will fail to
        # start). Note extract_my_id determines membership solely based on IP, so
        # this logic is not future-proof against changing node names or ports.
        my_id=$(extract_my_id "${prior_member_list}")
        if [ -z "${my_id}" ]; then
          member_add
          cluster="${cluster},${this_node}"
        fi
      fi

      # Sleep to allow member_add to propagate to entire cluster because starting
      # the server subsequently expects all peers to agree on the cluster members
      sleep 2

      start_and_sync_etcd

      verify_peer_url
      echo ${etcd_pid} > ${PIDFILE}

      ;;

    stop)
      set +e
      /var/vcap/jobs/etcd/bin/etcd_network_diagnostics_run_ctl.sh stop
      set -e

      kill_and_wait ${PIDFILE}

      ;;

    *)

      echo "Usage: etcd_ctl {start|stop}"

      ;;

  esac
}

main "${@}"
